# jane street数据预测主要流程

目标：根据Feature进行预测，预测出交易的返回值四个resp，从而预测我们是否进行action，action取(0,1)

![image-20210303170327394](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210303170327394.png)

计分方式：

![image-20210304153013328](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210304153013328.png)

Data Description

This dataset contains an anonymized set of features, `feature_{0...129}`, representing real stock market data. Each row in the dataset represents a trading opportunity, for which you will be predicting an `action` value: 1 to make the trade and 0 to pass on it. Each trade has an associated `weight` and `resp`, which together represents a return on the trade. The `date` column is an integer which represents the day of the trade, while `ts_id` represents a time ordering. In addition to anonymized feature values, you are provided with metadata about the features in **features.csv**.

In the training set, **train.csv**, you are provided a `resp` value, as well as several other `resp_{1,2,3,4}` values that represent returns over different time horizons. These variables are not included in the test set. Trades with `weight = 0` were intentionally included in the dataset for completeness, although such trades will not contribute towards the scoring evaluation.

This is a code competition that relies on a time-series API to ensure models do not peek forward in time. To use the API, follow the instructions on the [Evaluation page](https://www.kaggle.com/c/jane-street-market-prediction/overview/evaluation). When you submit your notebook, it will be rerun on an unseen test:

- During the model training phase of the competition, this unseen test set is comprised of approximately 1 million rows of historical data.
- During the live forecasting phase, the test set will use periodically updated live market data.

Note that during the second (forecasting) phase of the competition, the notebook time limits will scale with the number of trades presented in the test set. Refer to the [Code Requirements](https://www.kaggle.com/c/jane-street-market-prediction/overview/code-requirements) for details.

Files：

- **train.csv** - the training set, contains historical data and returns
- **example_test.csv** - a mock test set which represents the structure of the unseen test set. *You will not be directly using the test set or sample submission in this competition, as the time-series API will get/set the test set and predictions.*
- **example_sample_submission.csv** - a mock sample submission file in the correct format
- **features.csv** - metadata pertaining to the anonymized features



## 1. 探索性数据分析（EDA）（10%）

### 1.1 数据概览

- 一共拥有138个属性，2390491条数据。

  - 138属性中，数字型共137个，字符型1个。

  - 缺失值为6762701个，占比2.1%。总体来说缺失值不大

- Feature:7,8,17,18,27,28,72,78,84,90,96,102,108,114缺失值超过14%

- Feature_64具有唯一值

- weight有17.1%的零值

  
  
  **匿名数据如何处理？**

答：本次比赛的匿名数据量多并且相互之间关联性较难判断，可使用热力图看出来各个属性之间的关系。但是在后续处理中，对高相关性的属性在去除的过程中并不能起到很好的效果。



### 1.2 属性分析

- 先把130个属性分个组，聚合一下，可能分出来10个组，把这十个组分别对rsp1234求相关性，对于相关性高的说明这组属性对这个取值影响较大，提一下权。

- 属性间的关系由30个tag表示，tag为True就是有这个关系，tag为False就说明没有这层关系，表格完整，无缺失值。

  ~~**1.如何进行tag的嵌入？**~~

  在处理过程中，发现挖掘tag之间的信息并不如直接对属性间的关系进行操作来的直接和省时间，由于tag信息缺失过多导致没法获得较好的效果。故放弃

- ~~Tag的唯一性，如果可以，使用tag对feature进行替换~~

- **Date：**日期
  
  - 整个日期分布于0-500天之间，预计为两年间的每个交易日的操作。
  - 在观察与时间有关的特征时，人们不禁会注意到，其中许多特征似乎在第85天左右（*即*≈4个月后）就改变了性格。在观察85天为分界线时，day<85的波动较大，所以进行了删除。









## 2. 特征工程（40%）

- 删去了前85天的取值


- 尝试计算相关性，并取相关性大于0.9的属性进行删除。希望能获得较好的效果，代码如下：


```python
#计算两两的相关性，返回相关性大于0.9的列表
def detect_correlated_features(df,threshold=0.5):
    """This function will try detect features who have correlation grower than the introduced 
     threshold value.

@param df(DataFrame): The dataframe who resume the correlation values between features.
 @param threshold(int) : the threshold that the function, will use as reference to detect
                         correlated features.
 @return list(List): list of tuple, who resume features that have correlation grower than
                       the introduced threshold.
 """
correlated= defaultdict(list)
for col in df.columns:
    dex = list(df.columns).index(col)
    for ind in df.index[dex+1:] :
        if df.loc[col,ind] > threshold:
           correlated[col].append (ind)
            
return correlated     
```

- ~~使得resp_0,resp_1,resp_2,resp_3,全部大于0时执行act~~

- 使得resp>0时执行resp

- ~~使用回归函数填充一部分缺失值，另一部分使用均值填充~~

  ```python
  
  # feature
  for f in features_with_missing_values :
      model = LinearRegression()
      if  len(correlated_features[f]) > 0 :
          correlated = correlated_features[f][0]
          if correlated in train.columns :
             model.fit(train.loc[(train[correlated].notna()) & (train[f].notna()),correlated].values.reshape(-1,1),\
                train.loc[(train[correlated].notna()) & (train[f].notna()),f])
             values_to_impute = train_df.loc[(train[f].isna()) & (train[correlated].notna()),f]
             imputer = train.loc[(train[f].isna())&(train[correlated].notna()),correlated].values
             if (len(values_to_impute) > 0) & (len(imputer) > 0) :
                train_df.loc[(train[f].isna()) & (train[correlated].notna()),f] = model.predict(train.loc[(train[f].isna())&(train[correlated].notna()),correlated].values.\
                                                        reshape(-1,1))
  ```

- ~~使用前项填充~~

- 使用均值填充

- 使用weight>0的项目进行训练，weight不大于0的项目进行忽略。

- 将数据分为5折，每次逐渐更多的数据投入使用

- 将所有的数据由float64转换为float32，使得内存数量大大减小，不然后期可能会超时

  ```python
  train = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns})
  ```

  

## 3. 模型选择（30%）

### 3.1 Baseline：Encoder+MLP（8333）

**Encoder+MLP**

使用编码器的想法是去噪数据。在多次尝试使用无监督自动编码器后，选择了一个瓶颈编码器，因为这将保留内部特性关系。

~~**验证方法：PurgedGroupTimeSeriesSplit**~~ 无效

Time Series cross-validator variant with non-overlapping groups.
    Allows for a gap in groups to avoid potentially leaking info from train into test if the model has windowed or lag features.
    Provides train/test indices to split time series data samples that are observed at fixed time intervals according to a third-party provided group.
    In each split, test indices must be higher than before, and thus shuffling in cross validator is inappropriate.
    This cross-validation object is a variation of :class:`KFold`.
    In the kth split, it returns first k folds as train set and the (k+1)th fold as test set.
    The same group will not appear in two different folds (the number of distinct groups has to be at least equal to the number of folds).
    Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them.
    Read more in the :ref:`User Guide <cross_validation>`.

具有非重叠组的时间序列交叉验证程序变体。

如果模型具有窗口或滞后特性，则允许组中存在间隙，以避免潜在的信息从训练集泄漏到测试中。

为根据第三方提供的组在固定时间间隔观察到的时间序列数据样本提供训练/测试索引。

在每次分割中，测试索引必须比之前更高，因此在交叉验证器中洗牌是不合适的。

此交叉验证对象是：class:`KFold`的变体。

在第k次拆分中，它返回第一个k次折叠作为训练集，返回第（k+1）次折叠作为测试集。

同一组不会出现在两个不同的折叠中（不同组的数量必须至少等于折叠的数量）。

注意，与标准交叉验证方法不同，连续训练集是之前训练集的超集。

#### 3.1.1 Encoder自动编码器

**自动编码器**概念及学习：

自动编码器用于高维复杂数据处理，是一种无监督学习算法，它使用了反向传播算法，并让目标值等于输入值，比如y(i)=x(i) ，一般用于降维和特征学习。详见：https://www.jiqizhixin.com/articles/2017-09-23-4

![img](https://image.jiqizhixin.com/uploads/editor/7492d1db-d493-4dad-80aa-16f0fe259bc7/1525965553420.jpeg)

换句话说，它尝试逼近一个恒等函数，从而使得输出x(2)接近于输入x(1) 。恒等函数虽然看上去不太有学习的意义，但是当我们为自编码神经网络加入某些限制，比如限定隐藏神经元的数量，我们就可以从输入数据中发现一些有趣的结构。

举例来说，假设某个自编码神经网络的输入x 是一张 10×10图像（共100个像素）的像素灰度值，于是 n=100 ，其隐藏层L2中有50个隐藏神经元。

注意，输出也是100维。由于只有50个隐藏神经元，我们迫使自编码神经网络去学习输入数据的压缩表示，也就是说，它必须从50维的隐藏神经元激活度向量a(2)中重构出100维的像素灰度值输入x 。

一般来说，自编码器Autoencoder是神经网络中的一种。这个网络可以视为两部分：编码器函数encoder，和解码器decoder。

自编码器分类：

1. 去噪自动编码器

2. 稀疏自动编码器

3. 变分自动编码器（VAE）

4. 收缩自动编码器（CAE/contractive autoencoder）



Code：

```python
def create_autoencoder(input_dim,output_dim,noise=0.05):
    i = Input(input_dim)
    encoded = BatchNormalization()(i)
    encoded = GaussianNoise(noise)(encoded)#加噪提升鲁棒性
    encoded = Dense(64,activation='relu')(encoded)#降维成为64维
    decoded = Dropout(0.2)(encoded)
    decoded = Dense(input_dim,name='decoded')(decoded)
    x = Dense(32,activation='relu')(decoded)
    x = BatchNormalization()(x)
    x = Dropout(0.2)(x)
    x = Dense(32,activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dropout(0.2)(x)    
    x = Dense(output_dim,activation='sigmoid',name='label_output')(x)
    
    encoder = Model(inputs=i,outputs=encoded)
    autoencoder = Model(inputs=i,outputs=[decoded,x])
    
    autoencoder.compile(optimizer=Adam(0.005),loss={'decoded':'mse','label_output':'binary_crossentropy'})
    return autoencoder, encoder
```
#### 3.1.2 MLP多层感知机

在训练阶段，我们使用encoder编码后的向量作为网络输入，主要有四层隐层

```python
def create_model(input_dim,output_dim,encoder):
    inputs = Input(input_dim)
    x = encoder(inputs)#自编码
    x = Concatenate()([x,inputs]) #use both raw and encoded features
    x = BatchNormalization()(x)
    x = Dropout(0.13)(x)
    
    hidden_units = [384, 896, 896, 394]
    for idx, hidden_unit in enumerate(hidden_units):
        x = Dense(hidden_unit)(x)
        x = BatchNormalization()(x)
        x = Lambda(tf.keras.activations.relu)(x)
        x = Dropout(0.25)(x)
    x = Dense(output_dim,activation='sigmoid')(x)
    model = Model(inputs=inputs,outputs=x)
    model.compile(optimizer=Adam(0.0001),loss=BinaryCrossentropy(label_smoothing=0.001),metrics=[tf.keras.metrics.AUC(name = 'auc')])
    return model
```

- Batch Normalization，简称BatchNorm或BN，翻译为“批归一化”，是神经网络中一种特殊的层，如今已是各种流行网络的标配。

  Ioffe and Szegedy在[文章](https://arxiv.org/abs/1805.11604)中说，**BN可以防止梯度爆炸或弥散、可以提高训练时模型对于不同超参（学习率、初始化）的鲁棒性、可以让大部分的激活函数能够远离其饱和区域**。作者认为，BN能够work的真正原因在于***BN重新改变了优化问题，使得优化空间变得非常平滑。\***

  *饱和：假设h（x）是一个激活函数。*

  *1.当我们的x趋近于正无穷，激活函数的导数趋近于0，那么我们称之为右饱和。*

  *2.当我们的x趋近于负无穷，激活函数的导数趋近于0，那么我们称之为左饱和。*

  *当一个函数既满足左饱和又满足右饱和的时候我们就称之为饱和，典型的函数有Sigmoid，Tanh函数。*

  *3.对于任意的x，如果存在常数c，当x>c时，恒有=0，则称其为右硬饱和。如果对于任意的x，如果存在常数c，当x<c时，恒有=0,则称其为左硬饱和。既满足左硬饱和又满足右硬饱和的我们称这种函数为硬饱和。*

  *4.对于任意的x，如果存在常数c，当x>c时，恒有趋近于0，则称其为右软饱和。如果对于任意的x，如果存在常数c，当x<c时，恒有趋近于0,则称其为左软饱和。既满足左软饱和又满足右软饱和的我们称这种函数为软饱和*。

  *在神经网络中, 数据分布对训练会产生影响. 比如某个神经元 x 的值为1, 某个 Weights 的初始值为 0.1, 这样后一层神经元计算结果就是 Wx = 0.1; 又或者 x = 20, 这样 Wx 的结果就为 2. 现在还不能看出什么问题, 但是, 当我们加上一层激励函数, 激活这个 Wx 值的时候, 问题就来了. 如果使用 像 tanh 的激励函数, Wx 的激活值就变成了 ~0.1 和 ~1, 接近于 1 的部已经处在了 激励函数的饱和阶段, 也就是如果 x 无论再怎么扩大, tanh 激励函数输出值也还是 接近1. 换句话说, 神经网络在初始阶段已经不对那些比较大的 x 特征范围 敏感了. 这样很糟糕, 想象我轻轻拍自己的感觉和重重打自己的感觉居然没什么差别, 这就证明我的感官系统失效了. 当然我们是可以用之前提到的对数据做 normalization 预处理, 使得输入的 x 变化范围不会太大, 让输入值经过激励函数的敏感部分. 但刚刚这个不敏感问题不仅仅发生在神经网络的输入层, 而且在隐藏层中也经常会发生.*

  **BN所处的位置一般是dense层后，激活层前**

- ```python
  keras.layers.core.Lambda(function, output_shape=None, mask=None, arguments=None)
  ```

  本函数用以对上一层的输出施以任何Theano/TensorFlow表达式。

  如果你只是想对流经该层的数据做个变换，而这个变换本身没有什么需要学习的参数，那么直接用Lambda Layer是最合适的了。

- 标签光滑smooth_label:

  Lable Smoothing
  是分类问题中错误标注的一种解决方法。

  对于分类问题，特别是多分类问题，常常把向量转换成one-hot-vector（独热向量）
  one-hot带来的问题：（对于独热的简单解释：https://blog.csdn.net/qq_43211132/article/details/96141409）
  对于损失函数，我们需要用预测概率去拟合真实概率，而拟合one-hot的真实概率函数会带来两个问题：
  1)无法保证模型的泛化能力，容易造成过拟合；
  2) 全概率和0概率鼓励所属类别和其他类别之间的差距尽可能加大，而由梯度有界可知，这种情况很难适应。会造成模型过于相信预测的类别。

  使用下面的 label smoothing 可以缓解这个问题：

  原理：对于以Dirac函数分布的真实标签，我们将它变成分为两部分获得（替换）。

  第一部分：将原本Dirac分布的标签变量替换为(1 - ϵ)的Dirac函数；

  第二部分：以概率 ϵ ，在u(k) 中份分布的随机变量（u（k）是类别分之一）

### 3.2 深度模型DNN(10122)

在实现MLP+encoder后，在论坛风向的驱使下，我使用了由keras写的DNN的模型，具体模型的参数如下：

```python
"""
batch_size = 5000
hidden_units = [150, 150, 150]
dropout_rates = [0.20, 0.20, 0.20, 0.20]
label_smoothing = 1e-2
learning_rate = 1e-3
"""
def create_mlp(
    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate
):

    inp = tf.keras.layers.Input(shape=(num_columns,))
    inp_1 = tf.keras.backend.square(inp)
    
    x = tf.keras.layers.BatchNormalization()(inp)
    x = tf.keras.layers.Dropout(dropout_rates[0])(x)
    for i in range(len(hidden_units)):
        x = tf.keras.layers.Dense(hidden_units[i])(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)
        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)

    x_1 = tf.keras.layers.BatchNormalization()(inp_1)
    x_1 = tf.keras.layers.Dropout(dropout_rates[0])(x_1)
    for i in range(len(hidden_units)):
        x_1 = tf.keras.layers.Dense(hidden_units[i])(x_1)
        x_1 = tf.keras.layers.BatchNormalization()(x_1)
        x_1 = tf.keras.layers.Activation(tf.keras.activations.swish)(x_1)
        x_1 = tf.keras.layers.Dropout(dropout_rates[i + 1])(x_1)


    x = tf.keras.layers.Dense(num_labels)(x)
    out = tf.keras.layers.Activation("sigmoid")(x)

    model = tf.keras.models.Model(inputs=inp, outputs=out)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),
        metrics=tf.keras.metrics.AUC(name="AUC"),
    )

    return model
```

Total params: 136,045
Trainable params: 133,725
Non-trainable params: 2,320

**依靠深度刷上去的公榜高分，在一定程度上存在训练集过拟合的风险。在后期提交时候慎重！**

### 3.3 pytorch&tf集成（11441）

#### 3.3.1 pytorch模型（单模型：9932）：

```python
class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.batch_norm0 = nn.BatchNorm1d(len(all_feat_cols))
        self.dropout0 = nn.Dropout(0.2)

        dropout_rate = 0.2
        hidden_size = 256
        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)
        self.batch_norm1 = nn.BatchNorm1d(hidden_size)
        self.dropout1 = nn.Dropout(dropout_rate)

        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)
        self.batch_norm2 = nn.BatchNorm1d(hidden_size)
        self.dropout2 = nn.Dropout(dropout_rate)

        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)
        self.batch_norm3 = nn.BatchNorm1d(hidden_size)
        self.dropout3 = nn.Dropout(dropout_rate)

        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)
        self.batch_norm4 = nn.BatchNorm1d(hidden_size)
        self.dropout4 = nn.Dropout(dropout_rate)

        self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))

        self.Relu = nn.ReLU(inplace=True)
        self.PReLU = nn.PReLU()
        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)
        # self.GeLU = nn.GELU()
        self.RReLU = nn.RReLU()

    def forward(self, x):
        x = self.batch_norm0(x)
        x = self.dropout0(x)

        x1 = self.dense1(x)
        x1 = self.batch_norm1(x1)
        # x = F.relu(x)
        # x = self.PReLU(x)
        x1 = self.LeakyReLU(x1)
        x1 = self.dropout1(x1)

        x = torch.cat([x, x1], 1)

        x2 = self.dense2(x)
        x2 = self.batch_norm2(x2)
        # x = F.relu(x)
        # x = self.PReLU(x)
        x2 = self.LeakyReLU(x2)
        x2 = self.dropout2(x2)

        x = torch.cat([x1, x2], 1)

        x3 = self.dense3(x)
        x3 = self.batch_norm3(x3)
        # x = F.relu(x)
        # x = self.PReLU(x)
        x3 = self.LeakyReLU(x3)
        x3 = self.dropout3(x3)

        x = torch.cat([x2, x3], 1)

        x4 = self.dense4(x)
        x4 = self.batch_norm4(x4)
        # x = F.relu(x)
        # x = self.PReLU(x)
        x4 = self.LeakyReLU(x4)
        x4 = self.dropout4(x4)

        x = torch.cat([x3, x4], 1)

        x = self.dense5(x)

        return x
```

- **ReLU 的缺点：**
  训练的时候很”脆弱”，很容易就”die”了
  例如，一个非常大的梯度流过一个 ReLU 神经元，更新过参数之后，这个神经元再也不会对任何数据有激活现象了，那么这个神经元的梯度就永远都会是 0.
  如果 learning rate 很大，那么很有可能网络中的 40% 的神经元都”dead”了。

- ~~使用PReLu~~

  **PReLU**（**参数化修正线性单元**）：Parametric Rectified Linear Unit带参数的ReLU

  ![PReLU vs. ReLU](https://img-blog.csdn.net/20160508143448263)

  如果ai是一个很小的固定值(如ai=0.01)，则PReLU退化为Leaky ReLU(LReLU)。

- **LeakyReLu**

  **Leaky ReLUs**：ReLU是将所有的负值都设为零，相反，Leaky ReLU是给所有负值赋予一个非零斜率。Leaky ReLU激活函数是在声学模型（2013）中首次提出的。以数学的方式我们可以表示为：

    ![img](http://p0.ifengimg.com/pmop/2017/0701/CFC5A1C95A84A6D8CF3FFC1DD30597782AEEAE57_size20_w740_h231.jpeg)ai是（1，+∞）区间内的固定参数。

- **随机纠正线性单元（RReLU）**
    “随机纠正线性单元”RReLU也是Leaky ReLU的一个变体。在RReLU中，负值的斜率在训练中是随机的，在之后的测试中就变成了固定的了。RReLU的亮点在于，在训练环节中，aji是从一个均匀的分布U(I,u)中随机抽取的数值。形式上来说，我们能得到以下结果：

  ![img](http://p0.ifengimg.com/pmop/2017/0701/B3F2F3EA627EBB55D88C8F8FB36942C56B350A4B_size14_w740_h221.jpeg)

#### 3.3.2 tensorflow（10607）

```python
def create_mlp(
    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate
):

    inp = tf.keras.layers.Input(shape=(num_columns,))
    x = tf.keras.layers.BatchNormalization()(inp)
    x = tf.keras.layers.Dropout(dropout_rates[0])(x)
    for i in range(len(hidden_units)):
        x = tf.keras.layers.Dense(hidden_units[i])(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)
        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)
    
    x = tf.keras.layers.Dense(num_labels)(x)
    out = tf.keras.layers.Activation("sigmoid")(x)

    model = tf.keras.models.Model(inputs=inp, outputs=out)
    model.compile(
        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),
        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),
        metrics=tf.keras.metrics.AUC(name="AUC"),
    )

    return model
```

- 本质上就是3.2的DNN模型修改参数后取得的最好的效果

#### 3.3.3 集成

在集成时，由两个模型分别做出预测，最终预测结果为各0.5权重。

### 3.4 emdedingMLP+LightGBM（7356）

#### 3.4.1 LightGBM(7488)

```python
params={"num_leaves":300,
       "max_bin":450,
       "feature_fraction":0.52,
       "bagging_fraction":0.52,
       "objective":"binary",
       "learning_rate":0.05,
       "boosting_type":"gbdt",
       "metric":"auc"
       }
models = [] # list of model , we will train 
for i in range(y_train.shape[1]):
    xtr,xval,ytr,yval = train_test_split(X_train ,y_train[:,i],test_size=0.2,stratify=y_train[:,i])
   
    d_train = lgbm.Dataset(xtr,label=ytr)
    d_eval = lgbm.Dataset(xval,label=yval,reference=d_train)
    clf = lgbm.train(params,d_train,valid_sets=[d_train,d_eval],num_boost_round=1000,\
                    early_stopping_rounds=50,verbose_eval=50)
```

由LightGBM产生的属性重要性的图表：

![img](https://www.kaggleusercontent.com/kf/54881340/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..U0L1pCdyT3jsrcQpyhlZKA.y_QB9kxELUD4ZvxDq675Mm9e-m-FowyfuiiQDT5_ICc7SibOnIqCtEKXamyLFw90xggi-7hwFv0vDDHAjSMH579s-L84DFza9kkPKwpuzEDUWE3jdK_K5sRmLUYldGRnF6cIN-Be31fSIzBkXtEc6nf6oYxu6NhXGwapJ_icJR7X6UmSZHHDZJ04e0If9uNNE--Wtvh1_8XuoJT_zt-O4c3wAeQ2R_uCeBLFn3FVtyvoddl-xyhaFnimpV86ytWrPTQtjdFxbTAS0hofQ90D6_LspX1R9mNTn7sHouVhswzLQ5C4gvqjxgsRi9qhPfzGMhUcdehBvuy9LyLLQH9J-STEYgwbMmilNL1HgzKq0P4mHdUcZHk54xSrx_4XVeLYo3D0dgw-gEafF0VpH0QMHxXUDNzRWKfew_DBO36_H3q-PzXCI78ISY8lwUQSACJQfRVmK-q1Q7XyNf0hh-V0AL05OfZfXIepr4Ostuwt5EP6v8Q_3AAeSW41N4O_a2rGflV3n0LKMIXwyxBk8oeNyeFX4kS0H7Z41XmZv8h8hPGQQMeqk7AyiFYBL66nmXWL1yYiqf4AXSHjHA-dogg-iNQYQekfXB3XZEBnmuT-2hHPVqHMJJm6qdmxOOVphxLCbIMtCj8cWUozBJKV5SvJFLCE3FQwbfRxVDc2irkgUZ8.672BcmAyXzQKOUuGlERyaQ/__results___files/__results___24_0.png)



## 4.优化及调参(20%)

#### 4.1 EnCoder+MLP参数调整思路

- 折数FOLD：4=>5

- 种子SEED：42=>1112

- 

- **EnCoder**：

  优化器学习率=0.0005

  损失标签平滑值=0.001

  每层之间Dropout=0.25

  ```python
  autoencoder.fit(X,(X,y),
                      epochs=1000,
                      batch_size=4096, 
                      validation_split=0.1,
                      callbacks=[EarlyStopping('val_loss',patience=10,restore_best_weights=True)])
  ```

  

- MLP模型参数：

  ```python
  model.compile(optimizer=Adam(0.0001),loss=BinaryCrossentropy(label_smoothing=0.001),metrics=[tf.keras.metrics.AUC(name = 'auc')])
  ```

## 5.结果反馈

在本次比赛中，得分最高的是使用双DNN集成的模型，达到了11441的最高分，公榜排名2%，但是此版本的代码存在严重的过拟合的可能性，在论坛中有不少对深度模型的质疑。在控制过拟合后公榜版本的分数可能会下降。

使用Encoder+MLP的模型，不会产生过拟合的情况，但是在公榜上的排名并不高，只有7356。

最终选用这两个版本进行提交

## 6.总结及警告

总结：

1. 此次简街大赛使用的是匿名数据集，对于首次参加大赛的我来说，特征工程近乎于无法完成的任务，所以选择了几乎舍弃特征工程，转而直接使用几乎无处理的数据进行操作。
2. 多模型集成的效果在大多数情况下优于单模型结构。
3. 学习了自编码器
4. 学习了模型集成
5. 学习到网格调参等一系列调参方式
6. 如何控制过拟合？